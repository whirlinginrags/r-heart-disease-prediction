source('~/tings/r heart disease prediction/test.R', chdir = TRUE)
library(randomForest)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
set.seed(123)#
#
# Model 1: Generalized Linear Model (GLM)#
model1 <- train(#
  target ~ ., #
  data = train_data, #
  method = "glm",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 2: k-Nearest Neighbors (knn)#
model2 <- train(#
  target ~ ., #
  data = train_data, #
  method = "knn",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 3: Random Forest (rf)#
model3 <- train(#
  target ~ ., #
  data = train_data, #
  method = "rf",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 4: Support Vector Machine with Radial Basis Function Kernel (svmRadial)#
model4 <- train(#
  target ~ ., #
  data = train_data, #
  method = "svmRadial",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 5: Extreme Gradient Boosting (xgbTree)#
model5 <- train(#
  target ~ ., #
  data = train_data, #
  method = "xgbTree",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Print results#
print("Model 1:")#
print(model1)#
print("Model 2:")#
print(model2)#
print("Model 3:")#
print(model3)#
print("Model 4:")#
print(model4)#
print("Model 5:")#
print(model5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
best_model <- model3  # Assuming Random Forest is the best-performing model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
set.seed(123)#
#
# Model 1: Generalized Linear Model (GLM)#
model1 <- train(#
  target ~ ., #
  data = train_data, #
  method = "glm",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 2: k-Nearest Neighbors (knn)#
model2 <- train(#
  target ~ ., #
  data = train_data, #
  method = "knn",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 3: Random Forest (rf)#
model3 <- train(#
  target ~ ., #
  data = train_data, #
  method = "rf",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 4: Support Vector Machine with Radial Basis Function Kernel (svmRadial)#
model4 <- train(#
  target ~ ., #
  data = train_data, #
  method = "svmRadial",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 5: Extreme Gradient Boosting (xgbTree)#
model5 <- train(#
  target ~ ., #
  data = train_data, #
  method = "xgbTree",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Print results#
print("Model 1:")#
print(model1)#
print("Model 2:")#
print(model2)#
print("Model 3:")#
print(model3)#
print("Model 4:")#
print(model4)#
print("Model 5:")#
print(model5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic (ROC) Curves", lwd = 2)#
lines(roc_curve2, col = "red", lwd = 2)#
lines(roc_curve3, col = "green", lwd = 2)#
lines(roc_curve4, col = "purple", lwd = 2)#
lines(roc_curve5, col = "orange", lwd = 2)#
legend("bottomright", legend = c("GLM", "knn", "Random Forest", "svmRadial", "xgbTree"), col = c("blue", "red", "green", "purple", "orange"), lwd = 2)#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
best_model <- model3  # Assuming Random Forest is the best-performing model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
set.seed(123)#
#
# Model 1: Generalized Linear Model (GLM)#
model1 <- train(#
  target ~ ., #
  data = train_data, #
  method = "glm",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 2: k-Nearest Neighbors (knn)#
model2 <- train(#
  target ~ ., #
  data = train_data, #
  method = "knn",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 3: Random Forest (rf)#
model3 <- train(#
  target ~ ., #
  data = train_data, #
  method = "rf",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 4: Support Vector Machine with Radial Basis Function Kernel (svmRadial)#
model4 <- train(#
  target ~ ., #
  data = train_data, #
  method = "svmRadial",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 5: Extreme Gradient Boosting (xgbTree)#
model5 <- train(#
  target ~ ., #
  data = train_data, #
  method = "xgbTree",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Print results#
print("Model 1:")#
print(model1)#
print("Model 2:")#
print(model2)#
print("Model 3:")#
print(model3)#
print("Model 4:")#
print(model4)#
print("Model 5:")#
print(model5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(main = "Receiver Operating Characteristic")#
lines(roc_curve1, col = "blue")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
best_model <- model3  # Assuming Random Forest is the best-performing model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
set.seed(123)#
#
# Model 1: Generalized Linear Model (GLM)#
model1 <- train(#
  target ~ ., #
  data = train_data, #
  method = "glm",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 2: k-Nearest Neighbors (knn)#
model2 <- train(#
  target ~ ., #
  data = train_data, #
  method = "knn",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 3: Random Forest (rf)#
model3 <- train(#
  target ~ ., #
  data = train_data, #
  method = "rf",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 4: Support Vector Machine with Radial Basis Function Kernel (svmRadial)#
model4 <- train(#
  target ~ ., #
  data = train_data, #
  method = "svmRadial",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 5: Extreme Gradient Boosting (xgbTree)#
model5 <- train(#
  target ~ ., #
  data = train_data, #
  method = "xgbTree",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Print results#
print("Model 1:")#
print(model1)#
print("Model 2:")#
print(model2)#
print("Model 3:")#
print(model3)#
print("Model 4:")#
print(model4)#
print("Model 5:")#
print(model5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
best_model <- model3  # Assuming Random Forest is the best-performing model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
set.seed(123)#
#
# Model 1: Generalized Linear Model (GLM)#
model1 <- train(#
  target ~ ., #
  data = train_data, #
  method = "glm",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 2: k-Nearest Neighbors (knn)#
model2 <- train(#
  target ~ ., #
  data = train_data, #
  method = "knn",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 3: Random Forest (rf)#
model3 <- train(#
  target ~ ., #
  data = train_data, #
  method = "rf",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 4: Support Vector Machine with Radial Basis Function Kernel (svmRadial)#
model4 <- train(#
  target ~ ., #
  data = train_data, #
  method = "svmRadial",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Model 5: Extreme Gradient Boosting (xgbTree)#
model5 <- train(#
  target ~ ., #
  data = train_data, #
  method = "xgbTree",#
  trControl = trainControl(method = "cv", number = 5),#
  metric = "Accuracy"#
)#
#
# Determine the best-performing model based on accuracy#
best_model <- list(model1, model2, model3, model4, model5)[which.max(c(model1$results$Accuracy, model2$results$Accuracy, model3$results$Accuracy, model4$results$Accuracy, model5$results$Accuracy))]#
#
# Print the best-performing model#
print("Best-Performing Model:")#
print(best_model)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results using multi_roc#
#
# Combine predictions and true labels#
predictions <- data.frame(#
  GLM = as.numeric(predict(model1, newdata = test_data)),#
  kNN = as.numeric(predict(model2, newdata = test_data)),#
  Random_Forest = as.numeric(predict(model3, newdata = test_data)),#
  SVM = as.numeric(predict(model4, newdata = test_data)),#
  XGBoost = as.numeric(predict(model5, newdata = test_data)),#
  Truth = as.numeric(test_data$target)#
)#
#
# Create ROC curves#
roc_multiclass <- multiclass.roc(predictions$Truth, predictions[, -ncol(predictions)], percent = TRUE)#
#
# Plot the ROC curves#
plot(roc_multiclass, col = c("blue", "red", "green", "purple", "orange"), lwd = 2, main = "Receiver Operating Characteristic (ROC) Curves")#
#
# Step 10: Save the Best Model#
# Save the best model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
saveRDS(model1, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Evaluate models#
models <- list(model1, model2, model3, model4, model5)#
#
# Display results for all models#
for (i in 1:length(models)) {#
  print(paste("Model", i, "Results:"))#
  print(models[[i]])#
}#
#
# Find the best-performing model based on accuracy#
accuracies <- sapply(models, function(model) model$results$Accuracy)#
best_model <- models[[which.max(accuracies)]]#
#
# Predictions#
pred <- predict(best_model, newdata = test_data)#
#
# Confusion Matrix#
conf_matrix <- confusionMatrix(pred, test_data$target)#
#
# Display results#
print("Best-Performing Model:")#
print(best_model)#
print("Confusion Matrix:")#
print(conf_matrix)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace best_model with the best-performing model)#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with hyperparameter tuning#
ctrl <- trainControl(method = "cv", number = 5, search = "random", tuneLength = 5)#
#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = ctrl)#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = ctrl)#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = ctrl)#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = ctrl)#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = ctrl)#
#
# Evaluate models#
models <- list(model1, model2, model3, model4, model5)#
#
# Display results for all models#
for (i in 1:length(models)) {#
  print(paste("Model", i, "Results:"))#
  print(models[[i]])#
}#
#
# Find the best-performing model based on accuracy#
accuracies <- sapply(models, function(model) model$results$Accuracy)#
best_model <- models[[which.max(accuracies)]]#
#
# Predictions#
pred <- predict(best_model, newdata = test_data)#
#
# Confusion Matrix#
conf_matrix <- confusionMatrix(pred, test_data$target)#
#
# Display results#
print("Best-Performing Model:")#
print(best_model)#
print("Confusion Matrix:")#
print(conf_matrix)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace best_model with the best-performing model)#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Evaluate models#
models <- list(model1, model2, model3, model4, model5)#
#
# Display results for all models#
for (i in 1:length(models)) {#
  print(paste("Model", i, "Results:"))#
  print(models[[i]])#
}#
#
# Find the best-performing model based on accuracy#
accuracies <- sapply(models, function(model) model$results$Accuracy)#
best_model <- models[[which.max(accuracies)]]#
#
# Predictions#
pred <- predict(best_model, newdata = test_data)#
#
# Confusion Matrix#
conf_matrix <- confusionMatrix(pred, test_data$target)#
#
# Display results#
print("Best-Performing Model:")#
print(best_model)#
print("Confusion Matrix:")#
print(conf_matrix)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace best_model with the best-performing model)#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (with and without normalization)#
# Display results without normalization#
summary(data)#
#
# Normalize numeric columns#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Display results with normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
cat("Results without normalization:\n")#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic (Without Normalization)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
saveRDS(model1, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Scale the new data using the same scaling parameters as the training data#
new_data[, numeric_columns] <- scale(new_data[, numeric_columns], center = attr(train_data[, numeric_columns], "scaled:center"), scale = attr(train_data[, numeric_columns], "scaled:scale"))#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
saveRDS(model1, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data_non_normalized <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (with normalization)#
data_normalized <- scale(data_non_normalized[, sapply(data_non_normalized, is.numeric)])#
#
# Display results without normalization#
summary(data_non_normalized)#
#
# Display results with normalization#
summary(data.frame(data_normalized, target = data_non_normalized$target))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data (for non-normalized data)#
numeric_columns_non_normalized <- sapply(data_non_normalized, is.numeric)#
data_non_normalized[, numeric_columns_non_normalized] <- apply(data_non_normalized[, numeric_columns_non_normalized], 2, replace_outliers)#
#
# Apply the function to columns with numeric data (for normalized data)#
numeric_columns_normalized <- sapply(data_normalized, is.numeric)#
data_normalized[, numeric_columns_normalized] <- apply(data_normalized[, numeric_columns_normalized], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data_non_normalized$new_feature <- data_non_normalized$oldpeak * data_non_normalized$thalach#
# data_normalized$new_feature <- data_normalized$oldpeak * data_normalized$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data_non_normalized$target <- as.factor(data_non_normalized$target)#
data_normalized$target <- as.factor(data_normalized$target)#
#
# Split data into training and testing sets (for non-normalized data)#
set.seed(123)#
train_index_non_normalized <- createDataPartition(data_non_normalized$target, p = 0.8, list = FALSE)#
train_data_non_normalized <- data_non_normalized[train_index_non_normalized, ]#
test_data_non_normalized <- data_non_normalized[-train_index_non_normalized, ]#
#
# Split data into training and testing sets (for normalized data)#
set.seed(123)#
train_index_normalized <- createDataPartition(data_normalized$target, p = 0.8, list = FALSE)#
train_data_normalized <- data_normalized[train_index_normalized, ]#
test_data_normalized <- data_normalized[-train_index_normalized, ]#
#
# Train models#
model1_non_normalized <- train(target ~ ., data = train_data_non_normalized, method = "glm", trControl = trainControl(method = "cv"))#
model2_non_normalized <- train(target ~ ., data = train_data_non_normalized, method = "knn", trControl = trainControl(method = "cv"))#
model3_non_normalized <- train(target ~ ., data = train_data_non_normalized, method = "rf", trControl = trainControl(method = "cv"))#
model4_non_normalized <- train(target ~ ., data = train_data_non_normalized, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5_non_normalized <- train(target ~ ., data = train_data_non_normalized, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Train models for normalized data#
model1_normalized <- train(target ~ ., data = train_data_normalized, method = "glm", trControl = trainControl(method = "cv"))#
model2_normalized <- train(target ~ ., data = train_data_normalized, method = "knn", trControl = trainControl(method = "cv"))#
model3_normalized <- train(target ~ ., data = train_data_normalized, method = "rf", trControl = trainControl(method = "cv"))#
model4_normalized <- train(target ~ ., data = train_data_normalized, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5_normalized <- train(target ~ ., data = train_data_normalized, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Evaluate models for non-normalized data#
models_non_normalized <- list(model1_non_normalized, model2_non_normalized, model3_non_normalized, model4_non_normalized, model5_non_normalized)#
#
# Evaluate models for normalized data#
models_normalized <- list(model1_normalized, model2_normalized, model3_normalized, model4_normalized, model5_normalized)#
#
# Display results for all models for non-normalized data#
for (i in 1:length(models_non_normalized)) {#
  print(paste("Model", i, "Results (Non-Normalized):"))#
  print(models_non_normalized[[i]])#
}#
#
# Display results for all models for normalized data#
for (i in 1:length(models_normalized)) {#
  print(paste("Model", i, "Results (Normalized):"))#
  print(models_normalized[[i]])#
}#
#
# Find the best-performing model based on accuracy for non-normalized data#
accuracies_non_normalized <- sapply(models_non_normalized, function(model) model$results$Accuracy)#
best_model_non_normalized <- models_non_normalized[[which.max(accuracies_non_normalized)]]#
#
# Find the best-performing model based on accuracy for normalized data#
accuracies_normalized <- sapply(models_normalized, function(model) model$results$Accuracy)#
best_model_normalized <- models_normalized[[which.max(accuracies_normalized)]]#
#
# Predictions for non-normalized data#
pred_non_normalized <- predict(best_model_non_normalized, newdata = test_data_non_normalized)#
#
# Predictions for normalized data#
pred_normalized <- predict(best_model_normalized, newdata = test_data_normalized)#
#
# Confusion Matrix for non-normalized data#
conf_matrix_non_normalized <- confusionMatrix(pred_non_normalized, test_data_non_normalized$target)#
#
# Confusion Matrix for normalized data#
conf_matrix_normalized <- confusionMatrix(pred_normalized, test_data_normalized$target)#
#
# Display results for non-normalized data#
print("Best-Performing Model (Non-Normalized):")#
print(best_model_non_normalized)#
print("Confusion Matrix (Non-Normalized):")#
print(conf_matrix_non_normalized)#
#
# Display results for normalized data#
print("Best-Performing Model (Normalized):")#
print(best_model_normalized)#
print("Confusion Matrix (Normalized):")#
print(conf_matrix_normalized)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models for non-normalized data#
roc_curve1_non_normalized <- roc(test_data_non_normalized$target, as.numeric(predict(model1_non_normalized, newdata = test_data_non_normalized)))#
roc_curve2_non_normalized <- roc(test_data_non_normalized$target, as.numeric(predict(model2_non_normalized, newdata = test_data_non_normalized)))#
roc_curve3_non_normalized <- roc(test_data_non_normalized$target, as.numeric(predict(model3_non_normalized, newdata = test_data_non_normalized)))#
roc_curve4_non_normalized <- roc(test_data_non_normalized$target, as.numeric(predict(model4_non_normalized, newdata = test_data_non_normalized)))#
roc_curve5_non_normalized <- roc(test_data_non_normalized$target, as.numeric(predict(model5_non_normalized, newdata = test_data_non_normalized)))#
#
# Visualize classifier results for all models for normalized data#
roc_curve1_normalized <- roc(test_data_normalized$target, as.numeric(predict(model1_normalized, newdata = test_data_normalized)))#
roc_curve2_normalized <- roc(test_data_normalized$target, as.numeric(predict(model2_normalized, newdata = test_data_normalized)))#
roc_curve3_normalized <- roc(test_data_normalized$target, as.numeric(predict(model3_normalized, newdata = test_data_normalized)))#
roc_curve4_normalized <- roc(test_data_normalized$target, as.numeric(predict(model4_normalized, newdata = test_data_normalized)))#
roc_curve5_normalized <- roc(test_data_normalized$target, as.numeric(predict(model5_normalized, newdata = test_data_normalized)))#
#
# Plot the ROC curves for non-normalized data#
plot(roc_curve1_non_normalized, col = "blue", main = "Receiver Operating Characteristic (Non-Normalized)")#
lines(roc_curve2_non_normalized, col = "red")#
lines(roc_curve3_non_normalized, col = "green")#
lines(roc_curve4_non_normalized, col = "purple")#
lines(roc_curve5_non_normalized, col = "orange")#
#
# Plot the ROC curves for normalized data#
plot(roc_curve1_normalized, col = "blue", main = "Receiver Operating Characteristic (Normalized)")#
lines(roc_curve2_normalized, col = "red")#
lines(roc_curve3_normalized, col = "green")#
lines(roc_curve4_normalized, col = "purple")#
lines(roc_curve5_normalized, col = "orange")#
#
# Step 10: Save the Best Models#
# Save the best models (replace best_model_non_normalized and best_model_normalized with the best-performing models)#
saveRDS(best_model_non_normalized, "best_model_non_normalized.rds")#
saveRDS(best_model_normalized, "best_model_normalized.rds")#
#
# Step 11: Predict with the Best Models#
# Load the best models#
best_model_non_normalized <- readRDS("best_model_non_normalized.rds")#
best_model_normalized <- readRDS("best_model_normalized.rds")#
#
# Predict with new data (for non-normalized data)#
new_data_non_normalized <- read.csv("newdata.csv")  # Replace "newdata_non_normalized.csv" with your new data file#
prediction_non_normalized <- predict(best_model_non_normalized, newdata = new_data_non_normalized)#
print("Prediction (Non-Normalized):")#
print(prediction_non_normalized)#
#
# Predict with new data (for normalized data)#
new_data_normalized <- read.csv("newdata.csv")  # Replace "newdata_normalized.csv" with your new data file#
prediction_normalized <- predict(best_model_normalized, newdata = new_data_normalized)#
print("Prediction (Normalized):")#
print(prediction_normalized)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace model1 with the best-performing model)#
saveRDS(model1, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(models, function(model) model$results$Accuracy)#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Evaluate models#
models <- list(model1, model2, model3, model4, model5)#
#
# Display results for all models#
for (i in 1:length(models)) {#
  print(paste("Model", i, "Results:"))#
  print(models[[i]])#
}#
#
# Find the best-performing model based on accuracy#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace best_model with the best-performing model)#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Normalize the numeric columns#
normalize <- function(x) {#
  (x - min(x)) / (max(x) - min(x))#
}#
#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, normalize)#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Evaluate models#
models <- list(model1, model2, model3, model4, model5)#
#
# Display results for all models#
for (i in 1:length(models)) {#
  print(paste("Model", i, "Results:"))#
  print(models[[i]])#
}#
#
# Find the best-performing model based on accuracy#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results for all models#
roc_curve1 <- roc(test_data$target, as.numeric(predict(model1, newdata = test_data)))#
roc_curve2 <- roc(test_data$target, as.numeric(predict(model2, newdata = test_data)))#
roc_curve3 <- roc(test_data$target, as.numeric(predict(model3, newdata = test_data)))#
roc_curve4 <- roc(test_data$target, as.numeric(predict(model4, newdata = test_data)))#
roc_curve5 <- roc(test_data$target, as.numeric(predict(model5, newdata = test_data)))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
# Save the best model (replace best_model with the best-performing model)#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Use caret's preProcess for normalization#
preproc <- preProcess(data, method = c("center", "scale"))#
data_norm <- predict(preproc, data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data_norm, is.numeric)#
data_norm[, numeric_columns] <- apply(data_norm[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data_norm$target <- as.factor(data_norm$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data_norm$target, p = 0.8, list = FALSE)#
train_data <- data_norm[train_index, ]#
test_data <- data_norm[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Display results without normalization#
summary(data)#
#
# Step 3: Normalization#
# Use caret's preProcess for normalization#
preproc <- preProcess(data, method = c("center", "scale"))#
data_norm <- predict(preproc, data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data_norm, is.numeric)#
data_norm[, numeric_columns] <- apply(data_norm[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data_norm$target <- as.factor(data_norm$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data_norm$target, p = 0.8, list = FALSE)#
train_data <- data_norm[train_index, ]#
test_data <- data_norm[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Display results without normalization#
summary(data)#
#
# Step 3: Normalization (scale between 0 and 1)#
normalize_0_1 <- function(x) {#
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, normalize_0_1)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Display results without normalization#
summary(data)#
#
# Step 3: Normalization (scale with mean 0 and standard deviation 1)#
data[, sapply(data, is.numeric)] <- scale(data[, sapply(data, is.numeric)])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Display the summary of the data after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Display the summary of the data after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization (without normalization)#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Display results without normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# Feature Extraction#
data$new_feature <- rowMeans(data[, c("oldpeak", "thalach")], na.rm = TRUE)#
#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# Feature Extraction#
data$new_feature <- data$age * data$chol#
#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Feature Extraction#
data <- mutate(data, new_feature = age * chol)#
#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Example: Creating a new feature by combining two existing features#
# Feature Extraction#
data$new_feature <- data$age * data$chol#
#
# Check the summary of the dataset after feature extraction#
summary(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Create a new feature by combining two existing features#
data <- data %>% mutate(new_feature = age * chol)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Create a new feature by combining two existing features#
#data <- data %>% mutate(new_feature = age * chol)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
data <- data %>% mutate(new_feature = age * chol)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
data$new_feature <- data$oldpeak + data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
data$new_feature <- data$oldpeak + data$thalach#
#
# Save the modified data frame to a new CSV file#
write.csv(data, "heart_with_new_feature.csv", row.names = FALSE)#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
data$new_feature <- data$oldpeak + data$thalach#
#
# Save the modified data frame to a new CSV file#
write.csv(data, "heart.csv", row.names = FALSE)#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
data$new_feature <- data$thalach * data$oldpeak#
#
# Save the modified data frame to a new CSV file#
write.csv(data, "heart.csv", row.names = FALSE)#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Display results without normalization#
summary(data)#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
head(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Load new data#
new_data <- read.csv("newdata.csv")#
#
# Ensure 'new_feature' is calculated correctly#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Predict with the best model#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
head(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"))#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Display results without normalization#
summary(data)#
#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Display results after normalization#
summary(data)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
head(data)#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1),#
                metric = "Accuracy",#
                iteration_range = c(1, 100))  # Adjust the range based on your needs#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy",#
                iteration_range = c(1, 100))  # Adjust the range based on your needs#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)  # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(~ifelse(is.na(.), mean(., na.rm = TRUE), .))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy",#
                iter = 100)#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
cat("Model 1:\n")#
print(conf_matrix1)#
cat("\nModel 2:\n")#
print(conf_matrix2)#
cat("\nModel 3:\n")#
print(conf_matrix3)#
cat("\nModel 4:\n")#
print(conf_matrix4)#
cat("\nModel 5:\n")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)  # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(~ifelse(is.na(.), mean(., na.rm = TRUE), .))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy",#
                iter = 100)#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data, type = "prob")[, 2]#
pred2 <- predict(model2, newdata = test_data, type = "prob")[, 2]#
pred3 <- predict(model3, newdata = test_data, type = "prob")[, 2]#
pred4 <- predict(model4, newdata = test_data, type = "prob")[, 2]#
pred5 <- predict(model5, newdata = test_data, type = "prob")[, 2]#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(factor(ifelse(pred1 > 0.5, 1, 0)), test_data$target)#
conf_matrix2 <- confusionMatrix(factor(ifelse(pred2 > 0.5, 1, 0)), test_data$target)#
conf_matrix3 <- confusionMatrix(factor(ifelse(pred3 > 0.5, 1, 0)), test_data$target)#
conf_matrix4 <- confusionMatrix(factor(ifelse(pred4 > 0.5, 1, 0)), test_data$target)#
conf_matrix5 <- confusionMatrix(factor(ifelse(pred5 > 0.5, 1, 0)), test_data$target)#
#
# Display results#
cat("Model 1:\n")#
print(conf_matrix1)#
cat("\nModel 2:\n")#
print(conf_matrix2)#
cat("\nModel 3:\n")#
print(conf_matrix3)#
cat("\nModel 4:\n")#
print(conf_matrix4)#
cat("\nModel 5:\n")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, pred1)#
roc_curve2 <- roc(test_data$target, pred2)#
roc_curve3 <- roc(test_data$target, pred3)#
roc_curve4 <- roc(test_data$target, pred4)#
roc_curve5 <- roc(test_data$target, pred5)#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data, type = "prob")[, 2]#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy",#
                iteration_range = c(1, 100))  # Adjust the range based on your needs#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Use preProcess for normalization#
preprocess_params <- preProcess(data[, numeric_columns], method = c("range"))#
data[, numeric_columns] <- predict(preprocess_params, newdata = data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy",#
                iteration_range = c(1, 100))  # Adjust the range based on your needs#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Calculate additional metrics: precision, recall, and F1 score#
get_metrics <- function(conf_matrix) {#
  sensitivity <- conf_matrix$byClass["Sensitivity"]#
  specificity <- conf_matrix$byClass["Specificity"]#
  precision <- conf_matrix$byClass["Pos Pred Value"]#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  return(c(Sensitivity = sensitivity, Specificity = specificity, Precision = precision, Recall = recall, F1_Score = f1_score))#
}#
#
metrics1 <- get_metrics(conf_matrix1)#
metrics2 <- get_metrics(conf_matrix2)#
metrics3 <- get_metrics(conf_matrix3)#
metrics4 <- get_metrics(conf_matrix4)#
metrics5 <- get_metrics(conf_matrix5)#
#
# Display additional metrics#
print("Additional Metrics for Model 1:")#
print(metrics1)#
print("Additional Metrics for Model 2:")#
print(metrics2)#
print("Additional Metrics for Model 3:")#
print(metrics3)#
print("Additional Metrics for Model 4:")#
print(metrics4)#
print("Additional Metrics for Model 5:")#
print(metrics5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data, type = "response")#
pred2 <- predict(model2, newdata = test_data, type = "response")#
pred3 <- predict(model3, newdata = test_data, type = "response")#
pred4 <- predict(model4, newdata = test_data, type = "response")#
pred5 <- predict(model5, newdata = test_data, type = "response")#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Calculate additional metrics: precision, recall, and F1 score#
get_metrics <- function(conf_matrix) {#
  sensitivity <- conf_matrix$byClass["Sensitivity"]#
  specificity <- conf_matrix$byClass["Specificity"]#
  precision <- conf_matrix$byClass["Pos Pred Value"]#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  return(c(Sensitivity = sensitivity, Specificity = specificity, Precision = precision, Recall = recall, F1_Score = f1_score))#
}#
#
metrics1 <- get_metrics(conf_matrix1)#
metrics2 <- get_metrics(conf_matrix2)#
metrics3 <- get_metrics(conf_matrix3)#
metrics4 <- get_metrics(conf_matrix4)#
metrics5 <- get_metrics(conf_matrix5)#
#
# Display additional metrics#
print("Additional Metrics for Model 1:")#
print(metrics1)#
print("Additional Metrics for Model 2:")#
print(metrics2)#
print("Additional Metrics for Model 3:")#
print(metrics3)#
print("Additional Metrics for Model 4:")#
print(metrics4)#
print("Additional Metrics for Model 5:")#
print(metrics5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data, type = "response")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data, type = "raw")#
pred2 <- predict(model2, newdata = test_data, type = "raw")#
pred3 <- predict(model3, newdata = test_data, type = "response")#
pred4 <- predict(model4, newdata = test_data, type = "response")#
pred5 <- predict(model5, newdata = test_data, type = "response")#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(factor(pred1, levels = levels(test_data$target)), test_data$target)#
conf_matrix2 <- confusionMatrix(factor(pred2, levels = levels(test_data$target)), test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
print(get_metrics(conf_matrix1))#
print("Model 2:")#
print(conf_matrix2)#
print(get_metrics(conf_matrix2))#
print("Model 3:")#
print(conf_matrix3)#
print(get_metrics(conf_matrix3))#
print("Model 4:")#
print(conf_matrix4)#
print(get_metrics(conf_matrix4))#
print("Model 5:")#
print(conf_matrix5)#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data, type = "raw")#
#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- lower_bound#
  x[x > upper_bound] <- upper_bound#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data, type = "raw")#
pred2 <- predict(model2, newdata = test_data, type = "raw")#
pred3 <- predict(model3, newdata = test_data, type = "response")#
pred4 <- predict(model4, newdata = test_data, type = "response")#
pred5 <- predict(model5, newdata = test_data, type = "response")#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(factor(pred1, levels = levels(test_data$target)), test_data$target)#
conf_matrix2 <- confusionMatrix(factor(pred2, levels = levels(test_data$target)), test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
print(get_metrics(conf_matrix1))#
print("Model 2:")#
print(conf_matrix2)#
print(get_metrics(conf_matrix2))#
print("Model 3:")#
print(conf_matrix3)#
print(get_metrics(conf_matrix3))#
print("Model 4:")#
print(conf_matrix4)#
print(get_metrics(conf_matrix4))#
print("Model 5:")#
print(conf_matrix5)#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data, type = "raw")#
#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Calculate additional metrics: precision, recall, and F1 score#
get_metrics <- function(conf_matrix) {#
  sensitivity <- conf_matrix$byClass["Sensitivity"]#
  specificity <- conf_matrix$byClass["Specificity"]#
  precision <- conf_matrix$byClass["Pos Pred Value"]#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  return(c(Sensitivity = sensitivity, Specificity = specificity, Precision = precision, Recall = recall, F1_Score = f1_score))#
}#
#
metrics1 <- get_metrics(conf_matrix1)#
metrics2 <- get_metrics(conf_matrix2)#
metrics3 <- get_metrics(conf_matrix3)#
metrics4 <- get_metrics(conf_matrix4)#
metrics5 <- get_metrics(conf_matrix5)#
#
# Display additional metrics#
print("Additional Metrics for Model 1:")#
print(metrics1)#
print("Additional Metrics for Model 2:")#
print(metrics2)#
print("Additional Metrics for Model 3:")#
print(metrics3)#
print("Additional Metrics for Model 4:")#
print(metrics4)#
print("Additional Metrics for Model 5:")#
print(metrics5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
cat("Model 1:\n")#
print(conf_matrix1)#
print(get_metrics(conf_matrix1))#
#
cat("Model 2:\n")#
print(conf_matrix2)#
print(get_metrics(conf_matrix2))#
#
cat("Model 3:\n")#
print(conf_matrix3)#
print(get_metrics(conf_matrix3))#
#
cat("Model 4:\n")#
print(conf_matrix4)#
print(get_metrics(conf_matrix4))#
#
cat("Model 5:\n")#
print(conf_matrix5)#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well, if applicable#
new_data[, numeric_columns] <- scale(new_data[, numeric_columns])#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
# Extract new feature if needed#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
# Make predictions#
new_predictions <- predict(best_model, newdata = new_data)#
cat("Predictions for new data:\n")#
print(new_predictions)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scales::rescale(data[, numeric_columns], to = c(0, 1))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results#
print("Model 1:")#
print(conf_matrix1)#
print("Model 2:")#
print(conf_matrix2)#
print("Model 3:")#
print(conf_matrix3)#
print("Model 4:")#
print(conf_matrix4)#
print("Model 5:")#
print(conf_matrix5)#
#
# Calculate additional metrics: precision, recall, and F1 score#
get_metrics <- function(conf_matrix) {#
  sensitivity <- conf_matrix$byClass["Sensitivity"]#
  specificity <- conf_matrix$byClass["Specificity"]#
  precision <- conf_matrix$byClass["Pos Pred Value"]#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  return(c(Sensitivity = sensitivity, Specificity = specificity, Precision = precision, Recall = recall, F1_Score = f1_score))#
}#
#
metrics1 <- get_metrics(conf_matrix1)#
metrics2 <- get_metrics(conf_matrix2)#
metrics3 <- get_metrics(conf_matrix3)#
metrics4 <- get_metrics(conf_matrix4)#
metrics5 <- get_metrics(conf_matrix5)#
#
# Display additional metrics#
print("Additional Metrics for Model 1:")#
print(metrics1)#
print("Additional Metrics for Model 2:")#
print(metrics2)#
print("Additional Metrics for Model 3:")#
print(metrics3)#
print("Additional Metrics for Model 4:")#
print(metrics4)#
print("Additional Metrics for Model 5:")#
print(metrics5)#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Custom normalization function#
normalize <- function(x) {#
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))#
}#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- lapply(data[, numeric_columns], normalize)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
print("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
print("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
print("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
print("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
print("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Custom normalization function#
normalize <- function(x) {#
  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))#
}#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- lapply(data[, numeric_columns], normalize)#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models with improved parameters#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"), tuneLength = 10)#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"), tuneLength = 10)#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 200, max_depth = 5, eta = 0.05, gamma = 0, colsample_bytree = 0.8, min_child_weight = 1, subsample = 0.8),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
print("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
print("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
print("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
print("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
print("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1), col = "blue", main = "Receiver Operating Characteristic - Model 1")#
roc_curve2 <- roc(test_data$target, as.numeric(pred2), col = "red", main = "Receiver Operating Characteristic - Model 2")#
roc_curve3 <- roc(test_data$target, as.numeric(pred3), col = "green", main = "Receiver Operating Characteristic - Model 3")#
roc_curve4 <- roc(test_data$target, as.numeric(pred4), col = "purple", main = "Receiver Operating Characteristic - Model 4")#
roc_curve5 <- roc(test_data$target, as.numeric(pred5), col = "orange", main = "Receiver Operating Characteristic - Model 5")#
#
# Plot the ROC curves#
plot(roc_curve1)#
lines(roc_curve2)#
lines(roc_curve3)#
lines(roc_curve4)#
lines(roc_curve5)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x[!x < lower_bound])#
  x[x > upper_bound] <- max(x[!x > upper_bound])#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
models <- list(#
  glm = train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv")),#
  knn = train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv")),#
  rf = train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv")),#
  svmRadial = train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv")),#
  xgbTree = train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
)#
#
# Predictions and Confusion Matrices#
conf_matrices <- list()#
for (i in seq_along(models)) {#
  model <- models[[i]]#
  pred <- predict(model, newdata = test_data)#
  conf_matrices[[i]] <- confusionMatrix(pred, test_data$target)#
}#
#
# Display results and additional metrics#
for (i in seq_along(models)) {#
  model_name <- names(models)[i]#
  print(paste("Model", i, "(", model_name, "):"))#
  print(conf_matrices[[i]])#
  cat("Additional Metrics for Model", i, "(", model_name, "):")#
  print(get_metrics(conf_matrices[[i]]))#
}#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curves <- list()#
for (i in seq_along(models)) {#
  model_name <- names(models)[i]#
  pred <- predict(models[[i]], newdata = test_data)#
  roc_curve <- roc(test_data$target, as.numeric(pred))#
  roc_curves[[i]] <- roc_curve#
  lines(roc_curve, col = rainbow(length(models))[i], lwd = 2, title = model_name)#
}#
#
# Plot the ROC curves#
plot(roc_curves[[1]], col = "black", main = "Receiver Operating Characteristic", lwd = 2)#
for (i in 2:length(roc_curves)) {#
  lines(roc_curves[[i]], col = rainbow(length(models))[i], lwd = 2)#
}#
#
# Step 10: Save the Best Model#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
models <- list(#
  glm_model = train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv")),#
  knn_model = train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv")),#
  rf_model = train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv")),#
  svm_model = train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv")),#
  xgb_model = train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
)#
#
# Evaluate models#
model_results <- lapply(models, function(model) {#
  pred <- predict(model, newdata = test_data)#
  conf_matrix <- confusionMatrix(pred, test_data$target)#
  metrics <- get_metrics(conf_matrix)#
  return(list(model = model, conf_matrix = conf_matrix, metrics = metrics))#
})#
#
# Display results and additional metrics#
for (result in model_results) {#
  print(result$model$method)#
  print(result$conf_matrix)#
  cat("Additional Metrics:")#
  print(result$metrics)#
}#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curves <- lapply(model_results, function(result) {#
  roc_curve <- roc(test_data$target, as.numeric(predict(result$model, newdata = test_data)))#
  return(roc_curve)#
})#
#
# Plot the ROC curves#
plot(roc_curves[[1]], col = "blue", main = "Receiver Operating Characteristic")#
for (i in 2:length(roc_curves)) {#
  lines(roc_curves[[i]], col = rainbow(length(roc_curves))[i])#
}#
#
# Step 10: Save the Best Model#
accuracies <- sapply(model_results, function(result) max(result$model$results$Accuracy))#
best_model <- model_results[[which.max(accuracies)]]#
saveRDS(best_model$model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model$model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
models <- list(#
  glm_model = train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv")),#
  knn_model = train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv")),#
  rf_model = train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv")),#
  svm_model = train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv")),#
  xgb_model = train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
)#
#
# Evaluate models#
model_results <- lapply(models, function(model) {#
  pred <- predict(model, newdata = test_data)#
  conf_matrix <- confusionMatrix(pred, test_data$target)#
  metrics <- get_metrics(conf_matrix)#
  return(list(model = model, conf_matrix = conf_matrix, metrics = metrics))#
})#
#
# Display results and additional metrics#
for (result in model_results) {#
  print(result$model$method)#
  print(result$conf_matrix)#
  cat("Additional Metrics:")#
  print(result$metrics)#
}#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with model names#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = "blue", lty = 1)#
lines(roc_curve2, col = "red", lty = 2)#
lines(roc_curve3, col = "green", lty = 3)#
lines(roc_curve4, col = "purple", lty = 4)#
lines(roc_curve5, col = "orange", lty = 5)#
#
# Add legend with model names#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1:5, cex = 0.8)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(model_results, function(result) max(result$model$results$Accuracy))#
best_model <- model_results[[which.max(accuracies)]]#
saveRDS(best_model$model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model$model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
models <- list(#
  glm_model = train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv")),#
  knn_model = train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv")),#
  rf_model = train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv")),#
  svm_model = train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv")),#
  xgb_model = train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
)#
#
# Evaluate models#
model_results <- lapply(models, function(model) {#
  pred <- predict(model, newdata = test_data)#
  conf_matrix <- confusionMatrix(pred, test_data$target)#
  metrics <- get_metrics(conf_matrix)#
  return(list(model = model, conf_matrix = conf_matrix, metrics = metrics))#
})#
#
# Display results and additional metrics#
for (result in model_results) {#
  print(result$model$method)#
  print(result$conf_matrix)#
  cat("Additional Metrics:")#
  print(result$metrics)#
}#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curves <- lapply(model_results, function(result) {#
  roc_curve <- roc(test_data$target, as.numeric(predict(result$model, newdata = test_data)))#
  return(roc_curve)#
})#
#
# Plot the ROC curves#
plot(roc_curves[[1]], col = "blue", main = "Receiver Operating Characteristic")#
for (i in 2:length(roc_curves)) {#
  lines(roc_curves[[i]], col = rainbow(length(roc_curves))[i])#
}#
#
# Step 10: Save the Best Model#
accuracies <- sapply(model_results, function(result) max(result$model$results$Accuracy))#
best_model <- model_results[[which.max(accuracies)]]#
saveRDS(best_model$model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model$model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = "blue", lty = 1, lwd = 2, legend = "Model 1 (glm)")#
lines(roc_curve2, col = "red", lty = 2, lwd = 2, legend = "Model 2 (knn)")#
lines(roc_curve3, col = "green", lty = 3, lwd = 2, legend = "Model 3 (rf)")#
lines(roc_curve4, col = "purple", lty = 4, lwd = 2, legend = "Model 4 (svmRadial)")#
lines(roc_curve5, col = "orange", lty = 5, lwd = 2, legend = "Model 5 (xgbTree)")#
#
# Add legend#
legend("bottomright", legend = c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1:5, lwd = 2)#
#
# Optionally, you can customize the legend further by adjusting parameters such as text size, background color, etc.#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = "blue", lty = 1, lwd = 2)#
lines(roc_curve2, col = "red", lty = 1, lwd = 2)#
lines(roc_curve3, col = "green", lty = 1, lwd = 2)#
lines(roc_curve4, col = "purple", lty = 1, lwd = 2)#
lines(roc_curve5, col = "orange", lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Optionally, you can customize the legend further by adjusting parameters such as text size, background color, etc.#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with the best model in the legend#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Identify the best-performing model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
best_model_name <- c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)")[best_model_index]#
#
# Plot the ROC curves with legends, highlighting the best model#
plot(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "black", "blue"), main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "black", "blue"), lty = 1, lwd = 2)#
#
lines(roc_curve2, col = ifelse(best_model_name == "Model 2 (knn)", "black", "red"), lty = 1, lwd = 2)#
lines(roc_curve3, col = ifelse(best_model_name == "Model 3 (rf)", "black", "green"), lty = 1, lwd = 2)#
lines(roc_curve4, col = ifelse(best_model_name == "Model 4 (svmRadial)", "black", "purple"), lty = 1, lwd = 2)#
lines(roc_curve5, col = ifelse(best_model_name == "Model 5 (xgbTree)", "black", "orange"), lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c(paste("Model 1 (glm)", ifelse(best_model_name == "Model 1 (glm)", "(Best)", "")),#
                                  paste("Model 2 (knn)", ifelse(best_model_name == "Model 2 (knn)", "(Best)", "")),#
                                  paste("Model 3 (rf)", ifelse(best_model_name == "Model 3 (rf)", "(Best)", "")),#
                                  paste("Model 4 (svmRadial)", ifelse(best_model_name == "Model 4 (svmRadial)", "(Best)", "")),#
                                  paste("Model 5 (xgbTree)", ifelse(best_model_name == "Model 5 (xgbTree)", "(Best)", ""))),#
       col = c("black", "blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Optionally, you can customize the legend further by adjusting parameters such as text size, background color, etc.#
#
# Save the best model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
#
# Print the prediction#
print("Prediction using the Best Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with the best model in the legend#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Identify the best-performing model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
best_model_name <- c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)")[best_model_index]#
#
# Plot the ROC curves with legends, highlighting the best model#
plot(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "black", "blue"), main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "black", "blue"), lty = 1, lwd = 2)#
#
lines(roc_curve2, col = ifelse(best_model_name == "Model 2 (knn)", "black", "red"), lty = 1, lwd = 2)#
lines(roc_curve3, col = ifelse(best_model_name == "Model 3 (rf)", "black", "green"), lty = 1, lwd = 2)#
lines(roc_curve4, col = ifelse(best_model_name == "Model 4 (svmRadial)", "black", "purple"), lty = 1, lwd = 2)#
lines(roc_curve5, col = ifelse(best_model_name == "Model 5 (xgbTree)", "black", "orange"), lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c(paste("Model 1 (glm)", ifelse(best_model_name == "Model 1 (glm)", "(Best)", "")),#
                                  paste("Model 2 (knn)", ifelse(best_model_name == "Model 2 (knn)", "(Best)", "")),#
                                  paste("Model 3 (rf)", ifelse(best_model_name == "Model 3 (rf)", "(Best)", "")),#
                                  paste("Model 4 (svmRadial)", ifelse(best_model_name == "Model 4 (svmRadial)", "(Best)", "")),#
                                  paste("Model 5 (xgbTree)", ifelse(best_model_name == "Model 5 (xgbTree)", "(Best)", ""))),#
       col = c("black", "blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Save the best model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
#
# Print details of the best-performing model and the prediction#
cat("Best Performing Model:")#
print(best_model_name)#
print(best_model$results)#
cat("Confusion Matrix for the Best Model:")#
print(get_metrics(confusionMatrix(prediction, new_data$target)))#
print("Prediction using the Best Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with the best model in the legend#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Identify the best-performing model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
best_model_name <- c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)")[best_model_index]#
#
# Plot the ROC curves with legends, highlighting the best model#
plot(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), lty = 1, lwd = 2)#
#
lines(roc_curve2, col = ifelse(best_model_name == "Model 2 (knn)", "red", "black"), lty = 1, lwd = 2)#
lines(roc_curve3, col = ifelse(best_model_name == "Model 3 (rf)", "green", "black"), lty = 1, lwd = 2)#
lines(roc_curve4, col = ifelse(best_model_name == "Model 4 (svmRadial)", "purple", "black"), lty = 1, lwd = 2)#
lines(roc_curve5, col = ifelse(best_model_name == "Model 5 (xgbTree)", "orange", "black"), lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c(paste("Model 1 (glm)", ifelse(best_model_name == "Model 1 (glm)", " (Best)", "")),#
                                  paste("Model 2 (knn)", ifelse(best_model_name == "Model 2 (knn)", " (Best)", "")),#
                                  paste("Model 3 (rf)", ifelse(best_model_name == "Model 3 (rf)", " (Best)", "")),#
                                  paste("Model 4 (svmRadial)", ifelse(best_model_name == "Model 4 (svmRadial)", " (Best)", "")),#
                                  paste("Model 5 (xgbTree)", ifelse(best_model_name == "Model 5 (xgbTree)", " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Save the best model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
#
# Print details of the best-performing model and the prediction#
cat("Best Performing Model:")#
print(best_model_name)#
print("Confusion Matrix for the Best Model:")#
print(get_metrics(confusionMatrix(prediction, new_data$target)))#
print("Prediction using the Best Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(paste("Accuracy:", conf_matrix1$overall["Accuracy"]))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(paste("Accuracy:", conf_matrix2$overall["Accuracy"]))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(paste("Accuracy:", conf_matrix3$overall["Accuracy"]))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(paste("Accuracy:", conf_matrix4$overall["Accuracy"]))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(paste("Accuracy:", conf_matrix5$overall["Accuracy"]))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with the best model in the legend#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Identify the best-performing model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
best_model_name <- c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)")[best_model_index]#
#
# Plot the ROC curves with legends, highlighting the best model#
plot(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), lty = 1, lwd = 2)#
#
lines(roc_curve2, col = ifelse(best_model_name == "Model 2 (knn)", "red", "black"), lty = 1, lwd = 2)#
lines(roc_curve3, col = ifelse(best_model_name == "Model 3 (rf)", "green", "black"), lty = 1, lwd = 2)#
lines(roc_curve4, col = ifelse(best_model_name == "Model 4 (svmRadial)", "purple", "black"), lty = 1, lwd = 2)#
lines(roc_curve5, col = ifelse(best_model_name == "Model 5 (xgbTree)", "orange", "black"), lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c(paste("Model 1 (glm)", ifelse(best_model_name == "Model 1 (glm)", " (Best)", "")),#
                                  paste("Model 2 (knn)", ifelse(best_model_name == "Model 2 (knn)", " (Best)", "")),#
                                  paste("Model 3 (rf)", ifelse(best_model_name == "Model 3 (rf)", " (Best)", "")),#
                                  paste("Model 4 (svmRadial)", ifelse(best_model_name == "Model 4 (svmRadial)", " (Best)", "")),#
                                  paste("Model 5 (xgbTree)", ifelse(best_model_name == "Model 5 (xgbTree)", " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Save the best model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
#
# Print details of the best-performing model and the prediction#
cat("Best Performing Model:")#
print(best_model_name)#
print("Confusion Matrix for the Best Model:")#
conf_matrix_best <- confusionMatrix(prediction, new_data$target)#
print(conf_matrix_best)#
#
# Calculate additional metrics#
precision_best <- conf_matrix_best$byClass["Pos Pred Value"]#
recall_best <- conf_matrix_best$byClass["Sensitivity"]#
f1_score_best <- 2 * (precision_best * recall_best) / (precision_best + recall_best)#
#
cat("Additional Metrics for the Best Model:")#
cat("\nPrecision:", precision_best, "\n")#
cat("Recall (Sensitivity):", recall_best, "\n")#
cat("F1 Score:", f1_score_best, "\n")#
#
print("Prediction using the Best Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with the best model in the legend#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Identify the best-performing model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
best_model_name <- c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)")[best_model_index]#
#
# Plot the ROC curves with legends, highlighting the best model#
plot(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = ifelse(best_model_name == "Model 1 (glm)", "blue", "black"), lty = 1, lwd = 2)#
#
lines(roc_curve2, col = ifelse(best_model_name == "Model 2 (knn)", "red", "black"), lty = 1, lwd = 2)#
lines(roc_curve3, col = ifelse(best_model_name == "Model 3 (rf)", "green", "black"), lty = 1, lwd = 2)#
lines(roc_curve4, col = ifelse(best_model_name == "Model 4 (svmRadial)", "purple", "black"), lty = 1, lwd = 2)#
lines(roc_curve5, col = ifelse(best_model_name == "Model 5 (xgbTree)", "orange", "black"), lty = 1, lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c(paste("Model 1 (glm)", ifelse(best_model_name == "Model 1 (glm)", " (Best)", "")),#
                                  paste("Model 2 (knn)", ifelse(best_model_name == "Model 2 (knn)", " (Best)", "")),#
                                  paste("Model 3 (rf)", ifelse(best_model_name == "Model 3 (rf)", " (Best)", "")),#
                                  paste("Model 4 (svmRadial)", ifelse(best_model_name == "Model 4 (svmRadial)", " (Best)", "")),#
                                  paste("Model 5 (xgbTree)", ifelse(best_model_name == "Model 5 (xgbTree)", " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
#
# Print details of the best-performing model and the prediction#
cat("Best Performing Model:")#
print(best_model_name)#
#
# Print confusion matrix for the best model#
cat("Confusion Matrix for the Best Model:\n")#
conf_matrix_best <- confusionMatrix(prediction, new_data$target)#
print(conf_matrix_best)#
#
# Calculate additional metrics#
precision_best <- conf_matrix_best$byClass["Pos Pred Value"]#
recall_best <- conf_matrix_best$byClass["Sensitivity"]#
f1_score_best <- 2 * (precision_best * recall_best) / (precision_best + recall_best)#
#
cat("Additional Metrics for the Best Model:")#
cat("\nPrecision:", precision_best, "\n")#
cat("Recall (Sensitivity):", recall_best, "\n")#
cat("F1 Score:", f1_score_best, "\n")#
#
# Print prediction#
cat("Prediction using the Best Model:\n")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate additional metrics#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  error_rate <- 1 - accuracy#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[, 1])#
  metrics <- c(Accuracy = accuracy, ErrorRate = error_rate, Precision = precision, Recall = recall, F1Score = f1_score, Specificity = specificity)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate additional metrics#
get_metrics <- function(conf_matrix) {#
  # Extract the confusion matrix from the list#
  conf_matrix <- conf_matrix$confusionMatrix#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  error_rate <- 1 - accuracy#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[, 1])#
  metrics <- c(Accuracy = accuracy, ErrorRate = error_rate, Precision = precision, Recall = recall, F1Score = f1_score, Specificity = specificity)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate additional metrics#
get_metrics <- function(conf_matrix) {#
  # Extract the confusion matrix from the list#
  conf_matrix <- conf_matrix$confusionMatrix#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  error_rate <- 1 - accuracy#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  recall <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[, 1])#
  metrics <- c(Accuracy = accuracy, ErrorRate = error_rate, Precision = precision, Recall = recall, F1Score = f1_score, Specificity = specificity)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- scale(data[, numeric_columns])#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x[!x < lower_bound])#
  x[x > upper_bound] <- max(x[!x > upper_bound])#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
models <- list(#
  glm = train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv")),#
  knn = train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv")),#
  rf = train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv")),#
  svmRadial = train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv")),#
  xgbTree = train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
)#
#
# Predictions and Confusion Matrices#
conf_matrices <- list()#
for (i in seq_along(models)) {#
  model <- models[[i]]#
  pred <- predict(model, newdata = test_data)#
  conf_matrices[[i]] <- confusionMatrix(pred, test_data$target)#
}#
#
# Display results and additional metrics#
for (i in seq_along(models)) {#
  model_name <- names(models)[i]#
  print(paste("Model", i, "(", model_name, "):"))#
  print(conf_matrices[[i]])#
  cat("Additional Metrics for Model", i, "(", model_name, "):")#
  print(get_metrics(conf_matrices[[i]]))#
}#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curves <- list()#
for (i in seq_along(models)) {#
  model_name <- names(models)[i]#
  pred <- predict(models[[i]], newdata = test_data)#
  roc_curve <- roc(test_data$target, as.numeric(pred))#
  roc_curves[[i]] <- roc_curve#
  lines(roc_curve, col = rainbow(length(models))[i], lwd = 2, title = model_name)#
}#
#
# Plot the ROC curves#
plot(roc_curves[[1]], col = "black", main = "Receiver Operating Characteristic", lwd = 2)#
for (i in 2:length(roc_curves)) {#
  lines(roc_curves[[i]], col = rainbow(length(models))[i], lwd = 2)#
}#
#
# Step 10: Save the Best Model#
accuracies <- sapply(models, function(model) max(model$results$Accuracy))#
best_model <- models[[which.max(accuracies)]]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Check the balance of the target variable#
table(data$target)#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- quantile(x, 0.05)  # Replace with a less extreme value#
  x[x > upper_bound] <- quantile(x, 0.95)  # Replace with a less extreme value#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  metrics <- c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity, f1_score = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lty = 1, cex = 1)#
lines(roc_curve2, col = "red", lty = 1, cex = 1)#
lines(roc_curve3, col = "green", lty = 1, cex = 1)#
lines(roc_curve4, col = "purple", lty = 1, cex = 1)#
lines(roc_curve5, col = "orange", lty = 1, cex = 1)#
#
# Add a legend for better clarity#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Check the balance of the target variable#
table(data$target)#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- quantile(x, 0.05)  # Replace with a less extreme value#
  x[x > upper_bound] <- quantile(x, 0.95)  # Replace with a less extreme value#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  conf_matrix <- as.matrix(conf_matrix)#
  true_positives <- conf_matrix[2, 2]#
  true_negatives <- conf_matrix[1, 1]#
  false_positives <- conf_matrix[1, 2]#
  false_negatives <- conf_matrix[2, 1]#
  accuracy <- (true_positives + true_negatives) / sum(conf_matrix)#
  sensitivity <- true_positives / (true_positives + false_negatives)#
  specificity <- true_negatives / (true_negatives + false_positives)#
  precision <- true_positives / (true_positives + false_positives)#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  metrics <- c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity, f1_score = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lty = 1, cex = 1)#
lines(roc_curve2, col = "red", lty = 1, cex = 1)#
lines(roc_curve3, col = "green", lty = 1, cex = 1)#
lines(roc_curve4, col = "purple", lty = 1, cex = 1)#
lines(roc_curve5, col = "orange", lty = 1, cex = 1)#
#
# Add a legend for better clarity#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Check the balance of the target variable#
table(data$target)#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- quantile(x, 0.05)  # Replace with a less extreme value#
  x[x > upper_bound] <- quantile(x, 0.95)  # Replace with a less extreme value#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  conf_matrix <- as.matrix(conf_matrix)#
  true_positives <- conf_matrix[2, 2]#
  true_negatives <- conf_matrix[1, 1]#
  false_positives <- conf_matrix[1, 2]#
  false_negatives <- conf_matrix[2, 1]#
  accuracy <- (true_positives + true_negatives) / sum(conf_matrix)#
  sensitivity <- true_positives / (true_positives + false_negatives)#
  specificity <- true_negatives / (true_negatives + false_positives)#
  precision <- true_positives / (true_positives + false_positives)#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  metrics <- c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity, f1_score = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lty = 1, cex = 1)#
lines(roc_curve2, col = "red", lty = 1, cex = 1)#
lines(roc_curve3, col = "green", lty = 1, cex = 1)#
lines(roc_curve4, col = "purple", lty = 1, cex = 1)#
lines(roc_curve5, col = "orange", lty = 1, cex = 1)#
#
# Add legend with model names and specify the best performing model#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, cex = 0.8,#
       title = "Models", bty = "n")#
#
# Save the plot#
dev.copy(png, "roc_plot.png")#
dev.off()#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Check the balance of the target variable#
table(data$target)#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- quantile(x, 0.05)  # Replace with a less extreme value#
  x[x > upper_bound] <- quantile(x, 0.95)  # Replace with a less extreme value#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  conf_matrix <- as.matrix(conf_matrix)#
  true_positives <- conf_matrix[2, 2]#
  true_negatives <- conf_matrix[1, 1]#
  false_positives <- conf_matrix[1, 2]#
  false_negatives <- conf_matrix[2, 1]#
  accuracy <- (true_positives + true_negatives) / sum(conf_matrix)#
  sensitivity <- true_positives / (true_positives + false_negatives)#
  specificity <- true_negatives / (true_negatives + false_positives)#
  precision <- true_positives / (true_positives + false_positives)#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  metrics <- c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity, f1_score = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lty = 1, cex = 1)#
lines(roc_curve2, col = "red", lty = 1, cex = 1)#
lines(roc_curve3, col = "green", lty = 1, cex = 1)#
lines(roc_curve4, col = "purple", lty = 1, cex = 1)#
lines(roc_curve5, col = "orange", lty = 1, cex = 1)#
#
# Add legend with model names and specify the best performing model#
legend("bottomright", legend = c("Logistic Regression", "k-NN", "Random Forest", "SVM", "XGBoost"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, cex = 0.8,#
       title = "Models", bty = "n")#
#
# Save the plot#
dev.copy(png, "roc_plot.png")#
dev.off()#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Check the balance of the target variable#
table(data$target)#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- quantile(x, 0.05)  # Replace with a less extreme value#
  x[x > upper_bound] <- quantile(x, 0.95)  # Replace with a less extreme value#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  conf_matrix <- as.matrix(conf_matrix)#
  true_positives <- conf_matrix[2, 2]#
  true_negatives <- conf_matrix[1, 1]#
  false_positives <- conf_matrix[1, 2]#
  false_negatives <- conf_matrix[2, 1]#
  accuracy <- (true_positives + true_negatives) / sum(conf_matrix)#
  sensitivity <- true_positives / (true_positives + false_negatives)#
  specificity <- true_negatives / (true_negatives + false_positives)#
  precision <- true_positives / (true_positives + false_positives)#
  recall <- sensitivity#
  f1_score <- 2 * (precision * recall) / (precision + recall)#
  metrics <- c(accuracy = accuracy, sensitivity = sensitivity, specificity = specificity, f1_score = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lty = 1, cex = 1)#
lines(roc_curve2, col = "red", lty = 1, cex = 1)#
lines(roc_curve3, col = "green", lty = 1, cex = 1)#
lines(roc_curve4, col = "purple", lty = 1, cex = 1)#
lines(roc_curve5, col = "orange", lty = 1, cex = 1)#
#
# Identify the best model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
#
# Add legend with model names and specify the best performing model#
legend_text <- c("Logistic Regression", "k-NN", "Random Forest", "SVM", "XGBoost")#
legend_colors <- c("blue", "red", "green", "purple", "orange")#
legend_title <- "Models"#
best_model_name <- legend_text[which.max(accuracies)]#
#
legend("bottomright", legend = legend_text, col = legend_colors, lty = 1, cex = 0.8, title = legend_title, bty = "n")#
text(legend_text, col = legend_colors, x = 0.5, y = 0.5, labels = legend_text)#
text(best_model_name, col = legend_colors[which(legend_text == best_model_name)], x = 0.5, y = 0.5, labels = "Best Model", pos = 1)#
#
# Save the plot#
dev.copy(png, "roc_plot.png")#
dev.off()#
#
# Step 10: Save the Best Model#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = "blue", lwd = 2, type = "l", lty = 1, legend = paste("Model 1 (glm)", ifelse(best_model == model1, " (Best)", "")))#
lines(roc_curve2, col = "red", lwd = 2, type = "l", lty = 1, legend = paste("Model 2 (knn)", ifelse(best_model == model2, " (Best)", "")))#
lines(roc_curve3, col = "green", lwd = 2, type = "l", lty = 1, legend = paste("Model 3 (rf)", ifelse(best_model == model3, " (Best)", "")))#
lines(roc_curve4, col = "purple", lwd = 2, type = "l", lty = 1, legend = paste("Model 4 (svmRadial)", ifelse(best_model == model4, " (Best)", "")))#
lines(roc_curve5, col = "orange", lwd = 2, type = "l", lty = 1, legend = paste("Model 5 (xgbTree)", ifelse(best_model == model5, " (Best)", "")))#
#
# Add legend#
legend("bottomright", legend = c("Model 1 (glm)", "Model 2 (knn)", "Model 3 (rf)", "Model 4 (svmRadial)", "Model 5 (xgbTree)"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")  # type = "n" to create an empty plot#
#
# Add ROC curves#
lines(roc_curve1, col = "blue", lwd = 2, type = "l")#
lines(roc_curve2, col = "red", lwd = 2, type = "l")#
lines(roc_curve3, col = "green", lwd = 2, type = "l")#
lines(roc_curve4, col = "purple", lwd = 2, type = "l")#
lines(roc_curve5, col = "orange", lwd = 2, type = "l")#
#
# Add legend#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1, lwd = 2)#
#
# Highlight the best model in the legend#
best_model_index <- which.max(accuracies)#
legend("bottomright", legend = c("Best Model: Model", best_model_index),#
       col = c("black"), lty = 1, lwd = 2, bty = "n", cex = 0.8)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lwd = 2, cex = 1.5)#
lines(roc_curve2, col = "red", lwd = 2)#
lines(roc_curve3, col = "green", lwd = 2)#
lines(roc_curve4, col = "purple", lwd = 2)#
lines(roc_curve5, col = "orange", lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lwd = 2, cex = 1.2)#
#
# Highlight the ROC curve of the best-performing model in the legend#
best_model_name <- paste("Best Model (", which.max(accuracies), ")", sep = "")#
best_model_color <- c("blue", "red", "green", "purple", "orange")[which.max(accuracies)]#
lines(roc(get(test_data$target), as.numeric(get(paste("pred", which.max(accuracies), sep = "")))), col = best_model_color, lwd = 2, lty = 2)#
points(0, 1, pch = 15, col = best_model_color, cex = 1.5)#
text(0, 1, best_model_name, pos = 2, col = best_model_color, cex = 1.2)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", lwd = 2, cex = 1.5)#
lines(roc_curve2, col = "red", lwd = 2)#
lines(roc_curve3, col = "green", lwd = 2)#
lines(roc_curve4, col = "purple", lwd = 2)#
lines(roc_curve5, col = "orange", lwd = 2)#
#
# Add legend#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", "Best Model"),#
       col = c("blue", "red", "green", "purple", "orange", "black"), lwd = 2, cex = 1.2, lty = 1:2)#
#
# Highlight the ROC curve of the best-performing model in the legend#
best_model_name <- paste("Best Model (", which.max(accuracies), ")", sep = "")#
best_model_color <- c("blue", "red", "green", "purple", "orange")[which.max(accuracies)]#
lines(roc(get(test_data$target), as.numeric(get(paste("pred", which.max(accuracies), sep = "")))), col = "black", lwd = 2, lty = 2)#
points(0, 1, pch = 15, col = "black", cex = 1.5)#
text(0, 1, best_model_name, pos = 2, col = "black", cex = 1.2)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Highlight the best model in the legend#
best_model_name <- paste("Best Model:", which.max(accuracies))#
legend("bottomright", legend = best_model_name, col = "black", lty = 1, bty = "n", cex = 0.8)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend with model names and indication for the best model#
legend("bottomright", legend = c(paste("Model 1", ifelse(which.max(accuracies) == 1, " (Best)", "")),#
                                 paste("Model 2", ifelse(which.max(accuracies) == 2, " (Best)", "")),#
                                 paste("Model 3", ifelse(which.max(accuracies) == 3, " (Best)", "")),#
                                 paste("Model 4", ifelse(which.max(accuracies) == 4, " (Best)", "")),#
                                 paste("Model 5", ifelse(which.max(accuracies) == 5, " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend with model names and indication for the best model#
legend("bottomright", legend = c(paste("Model 1: Logistic Regression", ifelse(which.max(accuracies) == 1, " (Best)", "")),#
                                 paste("Model 2: k-Nearest Neighbors", ifelse(which.max(accuracies) == 2, " (Best)", "")),#
                                 paste("Model 3: Random Forest", ifelse(which.max(accuracies) == 3, " (Best)", "")),#
                                 paste("Model 4: Support Vector Machine", ifelse(which.max(accuracies) == 4, " (Best)", "")),#
                                 paste("Model 5: XGBoost", ifelse(which.max(accuracies) == 5, " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# ... (Previous code remains unchanged)#
#
# Display results and additional metrics for all models#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend with model names and indication for the best model#
legend("bottomright", legend = c(paste("Model 1: Logistic Regression", ifelse(which.max(accuracies) == 1, " (Best)", "")),#
                                 paste("Model 2: k-Nearest Neighbors", ifelse(which.max(accuracies) == 2, " (Best)", "")),#
                                 paste("Model 3: Random Forest", ifelse(which.max(accuracies) == 3, " (Best)", "")),#
                                 paste("Model 4: Support Vector Machine", ifelse(which.max(accuracies) == 4, " (Best)", "")),#
                                 paste("Model 5: XGBoost", ifelse(which.max(accuracies) == 5, " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Display information for the best model#
print("Best Performing Model:")#
prediction_best_model <- predict(best_model, newdata = new_data)#
print(prediction_best_model)#
cat("Additional Metrics for Best Performing Model:")#
conf_matrix_best_model <- confusionMatrix(prediction_best_model, new_data$target)#
print(get_metrics(conf_matrix_best_model))#
#
# Display final prediction#
print("Final Prediction:")#
print(prediction_best_model)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# ... (Previous code remains unchanged)#
#
# Display results and additional metrics for all models#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend with model names and indication for the best model#
legend("bottomright", legend = c(paste("Model 1: Logistic Regression", ifelse(which.max(accuracies) == 1, " (Best)", "")),#
                                 paste("Model 2: k-Nearest Neighbors", ifelse(which.max(accuracies) == 2, " (Best)", "")),#
                                 paste("Model 3: Random Forest", ifelse(which.max(accuracies) == 3, " (Best)", "")),#
                                 paste("Model 4: Support Vector Machine", ifelse(which.max(accuracies) == 4, " (Best)", "")),#
                                 paste("Model 5: XGBoost", ifelse(which.max(accuracies) == 5, " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Display information for the best model#
print("Best Performing Model:")#
prediction_best_model <- predict(best_model, newdata = new_data)#
cat("Confusion Matrix for Best Performing Model:")#
conf_matrix_best_model <- confusionMatrix(prediction_best_model, new_data$target)#
print(conf_matrix_best_model)#
cat("Additional Metrics for Best Performing Model:")#
print(get_metrics(conf_matrix_best_model))#
#
# Display final prediction#
print("Final Prediction:")#
print(prediction_best_model)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# ... (Previous code remains unchanged)#
#
# Display results and additional metrics for all models#
print("Model 1: Logistic Regression")#
prediction_model1 <- predict(model1, newdata = new_data)#
cat("Confusion Matrix for Model 1:")#
conf_matrix_model1 <- confusionMatrix(prediction_model1, new_data$target)#
print(conf_matrix_model1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix_model1))#
#
print("Model 2: k-Nearest Neighbors")#
prediction_model2 <- predict(model2, newdata = new_data)#
cat("Confusion Matrix for Model 2:")#
conf_matrix_model2 <- confusionMatrix(prediction_model2, new_data$target)#
print(conf_matrix_model2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix_model2))#
#
print("Model 3: Random Forest")#
prediction_model3 <- predict(model3, newdata = new_data)#
cat("Confusion Matrix for Model 3:")#
conf_matrix_model3 <- confusionMatrix(prediction_model3, new_data$target)#
print(conf_matrix_model3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix_model3))#
#
print("Model 4: Support Vector Machine")#
prediction_model4 <- predict(model4, newdata = new_data)#
cat("Confusion Matrix for Model 4:")#
conf_matrix_model4 <- confusionMatrix(prediction_model4, new_data$target)#
print(conf_matrix_model4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix_model4))#
#
print("Model 5: XGBoost")#
prediction_model5 <- predict(model5, newdata = new_data)#
cat("Confusion Matrix for Model 5:")#
conf_matrix_model5 <- confusionMatrix(prediction_model5, new_data$target)#
print(conf_matrix_model5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix_model5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend with model names and indication for the best model#
legend("bottomright", legend = c(paste("Model 1: Logistic Regression", ifelse(which.max(accuracies) == 1, " (Best)", "")),#
                                 paste("Model 2: k-Nearest Neighbors", ifelse(which.max(accuracies) == 2, " (Best)", "")),#
                                 paste("Model 3: Random Forest", ifelse(which.max(accuracies) == 3, " (Best)", "")),#
                                 paste("Model 4: Support Vector Machine", ifelse(which.max(accuracies) == 4, " (Best)", "")),#
                                 paste("Model 5: XGBoost", ifelse(which.max(accuracies) == 5, " (Best)", ""))),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Display information for the best model#
print("Best Performing Model:")#
prediction_best_model <- predict(best_model, newdata = new_data)#
cat("Confusion Matrix for Best Performing Model:")#
conf_matrix_best_model <- confusionMatrix(prediction_best_model, new_data$target)#
print(conf_matrix_best_model)#
cat("Additional Metrics for Best Performing Model:")#
print(get_metrics(conf_matrix_best_model))#
#
# Display final prediction#
print("Final Prediction:")#
print(prediction_best_model)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
cat("Model 1: Logistic Regression\n")#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
cat("\nModel 2: k-Nearest Neighbors\n")#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
cat("\nModel 3: Random Forest\n")#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
cat("\nModel 4: SVM (Radial)\n")#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
cat("\nModel 5: XGBoost (Best)\n")#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic", type = "n")#
lines(roc_curve1, col = "blue", lwd = 2, lty = 1)#
lines(roc_curve2, col = "red", lwd = 2, lty = 2)#
lines(roc_curve3, col = "green", lwd = 2, lty = 3)#
lines(roc_curve4, col = "purple", lwd = 2, lty = 4)#
lines(roc_curve5, col = "orange", lwd = 2, lty = 5)#
#
# Add legends#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-Nearest Neighbors", #
                                  "Model 3: Random Forest", "Model 4: SVM (Radial)", #
                                  "Model 5: XGBoost (Best)"),#
       col = c("blue", "red", "green", "purple", "orange"),#
       lty = 1:5, lwd = 2)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-Nearest Neighbors")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: Support Vector Machine")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost (Best)")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Print confusion matrix and additional metrics for the best-performing model#
print("Best Performing Model:")#
conf_matrix_best <- confusionMatrix(predict(best_model, newdata = test_data), test_data$target)#
print(conf_matrix_best)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(conf_matrix_best))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-Nearest Neighbors")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: Support Vector Machine")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost (Best)")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# ... (Previous code remains unchanged)#
#
# Print confusion matrix and additional metrics for the best-performing model#
print("Best Performing Model:")#
pred_best <- predict(best_model, newdata = test_data)#
conf_matrix_best <- confusionMatrix(pred_best, test_data$target)#
print(conf_matrix_best)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(conf_matrix_best))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred_best))  # ROC curve for the best-performing model#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the best-performing model#
#
# Add legend with model names#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-Nearest Neighbors", #
                                 "Model 3: Random Forest", "Model 4: Support Vector Machine",#
                                 "Model 5: XGBoost", "Best Performing Model"),#
       col = c("blue", "red", "green", "purple", "orange", "black"), lty = c(1, 1, 1, 1, 1, 2))#
#
# ... (Remaining code remains unchanged)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
cat("Model 1 (Logistic Regression):")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
cat("Model 2 (k-Nearest Neighbors):")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
cat("Model 3 (Random Forest):")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
cat("Model 4 (Support Vector Machine):")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
cat("Model 5 (XGBoost):")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Confusion Matrix and Additional Metrics for the Best Model#
best_pred <- predict(best_model, newdata = new_data)#
best_conf_matrix <- confusionMatrix(best_pred, new_data$target)#
cat("Confusion Matrix and Additional Metrics for the Best Model:")#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Model:")#
print(get_metrics(best_conf_matrix))#
#
# Print predictions#
cat("Predictions with the Best Model:")#
print(best_pred)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)#
  metrics <- c("Accuracy" = accuracy, "Sensitivity" = sensitivity, "Specificity" = specificity, "F1-Score" = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
cat("Model 1 (Logistic Regression):")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
cat("Model 2 (k-Nearest Neighbors):")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
cat("Model 3 (Random Forest):")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
cat("Model 4 (Support Vector Machine):")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
cat("Model 5 (XGBoost):")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Confusion Matrix and Additional Metrics for the Best Model#
best_pred <- predict(best_model, newdata = new_data)#
best_conf_matrix <- confusionMatrix(best_pred, new_data$target)#
cat("Confusion Matrix and Additional Metrics for the Best Model:")#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Model:")#
print(get_metrics(best_conf_matrix))#
#
# Print predictions#
cat("Predictions with the Best Model:")#
print(best_pred)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-Score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  precision <- conf_matrix[2, 2] / sum(conf_matrix[, 2])#
  f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)#
  metrics <- c("Accuracy" = accuracy, "Sensitivity" = sensitivity, "Specificity" = specificity, "F1-Score" = f1_score)#
  return(metrics)#
}#
#
# Display results and additional metrics#
cat("Model 1 (Logistic Regression):")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
cat("Model 2 (k-Nearest Neighbors):")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
cat("Model 3 (Random Forest):")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
cat("Model 4 (Support Vector Machine):")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
cat("Model 5 (XGBoost):")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legends#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
legend("bottomright", legend = c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5"),#
       col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
# Confusion Matrix and Additional Metrics for the Best Model#
best_pred <- predict(best_model, newdata = new_data)#
best_conf_matrix <- confusionMatrix(best_pred, new_data$target)#
cat("Confusion Matrix and Additional Metrics for the Best Model:")#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Model:")#
print(get_metrics(best_conf_matrix))#
#
# Print predictions#
cat("Predictions with the Best Model:")#
print(best_pred)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Step 9: Visualization of Classifier Results#
# Visualize classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Step 10: Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Step 11: Predict with the Best Model#
# Load the best model#
best_model <- readRDS("best_model.rds")#
#
# Predict with new data#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# ... (previous code)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_conf_matrix <- confusionMatrix(best_pred, test_data$target)#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# ... (previous code)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# ... (previous code)#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_conf_matrix <- confusionMatrix(best_pred, levels = levels(test_data$target))#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_conf_matrix <- confusionMatrix(best_pred, levels = levels(test_data$target))#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_conf_matrix <- confusionMatrix(best_pred, reference = test_data$target)#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
best_conf_matrix <- confusionMatrix(best_pred, reference = test_data$target)#
print(best_conf_matrix)#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model <- list(model1, model2, model3, model4, model5)[which.max(accuracies)]#
saveRDS(best_model, "best_model.rds")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost (Best)")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
load("/Users/whirlinginrags/tings/r heart disease prediction/best_model.rds")
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost (Best)")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve_best <- roc(test_data$target, as.numeric(best_pred))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", best_model_name), col = c("blue", "red", "green", "purple", "black"), lty = c(1, 1, 1, 1, 2))#
#
# ... (The rest of your code)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  print("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 2))#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black")  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black")  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# Uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)#
library(scales)#
#
# 1. Data should be visualized by analyzing the data.#
# Loading dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. In the pre-processing stage, missing data should be filled with the average value of that column.#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. Normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. Find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x[ x >= lower_bound & x <= upper_bound ])#
  x[x > upper_bound] <- max(x[ x >= lower_bound & x <= upper_bound ])#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# 5. Perform at least 1 new feature extraction#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. Classify the data with at least 5 classifiers#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. Show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. Show the confusion matrix for each classifier#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. Visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic (ROC)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(c(get_metrics(conf_matrix1)["Accuracy"], get_metrics(conf_matrix1)["Sensitivity"], get_metrics(conf_matrix1)["Specificity"], get_metrics(conf_matrix1)["F1_Score"])), " (Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(c(get_metrics(conf_matrix2)["Accuracy"], get_metrics(conf_matrix2)["Sensitivity"], get_metrics(conf_matrix2)["Specificity"], get_metrics(conf_matrix2)["F1_Score"])), " (Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(c(get_metrics(conf_matrix3)["Accuracy"], get_metrics(conf_matrix3)["Sensitivity"], get_metrics(conf_matrix3)["Specificity"], get_metrics(conf_matrix3)["F1_Score"])), " (Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(c(get_metrics(conf_matrix4)["Accuracy"], get_metrics(conf_matrix4)["Sensitivity"], get_metrics(conf_matrix4)["Specificity"], get_metrics(conf_matrix4)["F1_Score"])), " (Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(c(get_metrics(conf_matrix5)["Accuracy"], get_metrics(conf_matrix5)["Sensitivity"], get_metrics(conf_matrix5)["Specificity"], get_metrics(conf_matrix5)["F1_Score"])), " (Best)", ""))#
), fill = c("blue", "red", "green", "purple", "orange"))#
#
# 10. Save the model with the best accuracy.#
accuracies <- c(#
  get_metrics(conf_matrix1)["Accuracy"],#
  get_metrics(conf_matrix2)["Accuracy"],#
  get_metrics(conf_matrix3)["Accuracy"],#
  get_metrics(conf_matrix4)["Accuracy"],#
  get_metrics(conf_matrix5)["Accuracy"]#
)#
#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
#
# 11. When new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
#
# Predict with the best model#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the best performing model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost (Best)")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(best_pred))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", best_model_name), col = c("blue", "red", "green", "purple", "black"), lty = c(1, 1, 1, 1, 2))#
#
# Save the Best Model#
saveRDS(best_model, "best_model.rds")
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black", lty = 2)  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 2))#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
print("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
lines(roc_curve_best, col = "black")  # Add ROC curve for the Best Performing Model#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print("Confusion Matrix for the Best Performing Model:")#
print(best_conf_matrix)#
#
# Display additional metrics for the Best Performing Model#
best_metrics <- get_metrics(best_conf_matrix)#
if (!any(is.na(best_metrics))) {#
  cat("Additional Metrics for the Best Performing Model:")#
  print(best_metrics)#
} else {#
  print("Additional Metrics for the Best Performing Model could not be calculated.")#
}#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1: Logistic Regression")#
print(conf_matrix1)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2: k-NN")#
print(conf_matrix2)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3: Random Forest")#
print(conf_matrix3)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4: SVM Radial")#
print(conf_matrix4)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5: XGBoost")#
print(conf_matrix5)#
cat("Additional Metrics:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("Model 1: Logistic Regression", ifelse(1 == which.max(accuracies), "(Best)", "")),#
  paste("Model 2: k-NN", ifelse(2 == which.max(accuracies), "(Best)", "")),#
  paste("Model 3: Random Forest", ifelse(3 == which.max(accuracies), "(Best)", "")),#
  paste("Model 4: SVM Radial", ifelse(4 == which.max(accuracies), "(Best)", "")),#
  paste("Model 5: XGBoost", ifelse(5 == which.max(accuracies), "(Best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# Save the Best Model#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Predict with the Best Model#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("Prediction with the Best Performing Model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost (Best)")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# Install required packages (uncomment if not already installed)#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# Load libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  # Add this line to load the labeling package#
library(scales)    # Add this line to load the scales package#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix))) / sum(as.matrix(conf_matrix))#
  sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])#
  specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Step 1: Data Visualization#
# Load your dataset#
data <- read.csv("heart.csv")#
#
# Visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# Step 2: Handling Missing Data#
# Filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# Step 3: Normalization#
# Check which columns are numeric#
numeric_columns <- sapply(data, is.numeric)#
#
# Apply normalization to numeric columns#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# Step 4: Replace Outliers#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# Apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
# Step 5: Feature Extraction (optional, you can skip this if not needed)#
# Creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
# Step 6-8: Classification and Evaluation#
# Convert the target variable to a factor#
data$target <- as.factor(data$target)#
#
# Split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# Train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# Predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# Confusion Matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# Function to calculate accuracy, sensitivity, specificity, and F1-score#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# Display results and additional metrics#
print("Model 1:")#
print(conf_matrix1)#
cat("Additional Metrics for Model 1:")#
print(get_metrics(conf_matrix1))#
#
print("Model 2:")#
print(conf_matrix2)#
cat("Additional Metrics for Model 2:")#
print(get_metrics(conf_matrix2))#
#
print("Model 3:")#
print(conf_matrix3)#
cat("Additional Metrics for Model 3:")#
print(get_metrics(conf_matrix3))#
#
print("Model 4:")#
print(conf_matrix4)#
cat("Additional Metrics for Model 4:")#
print(get_metrics(conf_matrix4))#
#
print("Model 5:")#
print(conf_matrix5)#
cat("Additional Metrics for Model 5:")#
print(get_metrics(conf_matrix5))#
#
# Visualization of Classifier Results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
#
# Plot the ROC curves with legend#
plot(roc_curve1, col = "blue", main = "Receiver Operating Characteristic")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# Add legend#
legend("bottomright", legend = c("Model 1: Logistic Regression", "Model 2: k-NN", "Model 3: Random Forest", "Model 4: SVM Radial", "Model 5: XGBoost (Best)"), col = c("blue", "red", "green", "purple", "orange"), lty = 1)#
#
# Save the Best Model#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# Print the best model name#
best_model_name <- c("Logistic Regression", "k-NN", "Random Forest", "SVM Radial", "XGBoost (Best)")[best_model_index]#
cat("Best Performing Model:", best_model_name, "\n")#
#
# Display the Confusion Matrix and Additional Metrics of the Best Performing Model#
print("Best Performing Model:")#
best_pred <- predict(best_model, newdata = test_data)#
best_pred <- factor(best_pred, levels = levels(test_data$target))#
#
# Create a data frame for confusionMatrix#
conf_matrix_data <- data.frame(Predicted = best_pred, Reference = test_data$target)#
#
# Create a confusion matrix#
best_conf_matrix <- confusionMatrix(conf_matrix_data$Predicted, conf_matrix_data$Reference)#
print(best_conf_matrix)#
#
cat("Additional Metrics for the Best Performing Model:")#
print(get_metrics(best_conf_matrix))#
#
# Predict with the Best Model#
print("Predictions with the Best Model:")#
new_data <- read.csv("newdata.csv")  # Replace "newdata.csv" with your new data file#
# Ensure that the feature extraction step is performed on the new data as well#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
prediction <- predict(best_model, newdata = new_data)#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))  # Use the best model for ROC curve#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv")#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv") # change the newdata.csv to your data file for predictions. for testing purposes i have removed the target column from the dataset you have provided and predicted the results once again.#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
# uncomment the line below if any of the packages are not installed#
# install.packages(c("tidyverse", "caret", "e1071", "randomForest", "kernlab", "xgboost", "pROC", "labeling"))#
#
# libraries#
library(tidyverse)#
library(caret)#
library(e1071)#
library(randomForest)#
library(kernlab)#
library(xgboost)#
library(pROC)#
library(labeling)  #
library(scales)#
#
# 1. data should be visualized by analyzing the data.#
# loading dataset#
data <- read.csv("heart.csv")#
#
# visualize data#
summary(data)#
ggplot(data, aes(x = factor(target), fill = factor(target))) + geom_bar()#
#
# 2. in the pre-processing stage, missing data should be filled with the average value of that column.#
# filling missing data with mean#
data <- data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
#
# 3. normalization should be done#
numeric_columns <- sapply(data, is.numeric)#
#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
#
# 4. find outlier data and write a function to replace the outlier data with the maximum non-outlier value in that column.#
replace_outliers <- function(x) {#
  q <- quantile(x, c(0.25, 0.75))#
  iqr <- IQR(x)#
  lower_bound <- q[1] - 1.5 * iqr#
  upper_bound <- q[2] + 1.5 * iqr#
  x[x < lower_bound] <- max(x)#
  x[x > upper_bound] <- max(x)#
  return(x)#
}#
#
# apply the function to columns with numeric data#
data[, numeric_columns] <- apply(data[, numeric_columns], 2, replace_outliers)#
#
#  5. perform at least 1 new feature extraction#
# creating a new feature by combining two existing features#
data$new_feature <- data$oldpeak * data$thalach#
#
data$target <- as.factor(data$target)#
#
# 6. classify the data with at least 5 classifiers#
# split data into training and testing sets#
set.seed(123)#
train_index <- createDataPartition(data$target, p = 0.8, list = FALSE)#
train_data <- data[train_index, ]#
test_data <- data[-train_index, ]#
#
# train models#
model1 <- train(target ~ ., data = train_data, method = "glm", trControl = trainControl(method = "cv"))#
model2 <- train(target ~ ., data = train_data, method = "knn", trControl = trainControl(method = "cv"))#
model3 <- train(target ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv"))#
model4 <- train(target ~ ., data = train_data, method = "svmRadial", trControl = trainControl(method = "cv"))#
model5 <- train(target ~ ., data = train_data, method = "xgbTree", trControl = trainControl(method = "cv"),#
                tuneGrid = expand.grid(nrounds = 100, max_depth = 3, eta = 0.1, gamma = 0, colsample_bytree = 1, min_child_weight = 1, subsample = 1),#
                metric = "Accuracy")#
#
# predictions#
pred1 <- predict(model1, newdata = test_data)#
pred2 <- predict(model2, newdata = test_data)#
pred3 <- predict(model3, newdata = test_data)#
pred4 <- predict(model4, newdata = test_data)#
pred5 <- predict(model5, newdata = test_data)#
#
# confusion matrices#
conf_matrix1 <- confusionMatrix(pred1, test_data$target)#
conf_matrix2 <- confusionMatrix(pred2, test_data$target)#
conf_matrix3 <- confusionMatrix(pred3, test_data$target)#
conf_matrix4 <- confusionMatrix(pred4, test_data$target)#
conf_matrix5 <- confusionMatrix(pred5, test_data$target)#
#
# 7. show the accuracy, sensitivity, specificity, F1-Score values of the results of the classifiers#
get_metrics <- function(conf_matrix) {#
  accuracy <- sum(diag(as.matrix(conf_matrix$table))) / sum(as.matrix(conf_matrix$table))#
  sensitivity <- conf_matrix$table[2, 2] / sum(conf_matrix$table[2, ])#
  specificity <- conf_matrix$table[1, 1] / sum(conf_matrix$table[1, ])#
  f1_score <- 2 * (sensitivity * specificity) / (sensitivity + specificity)#
  return(c(Accuracy = accuracy, Sensitivity = sensitivity, Specificity = specificity, F1_Score = f1_score))#
}#
#
# 8. show the confusion matrix for each classifier#
print("model 1: logistic regression")#
print(conf_matrix1)#
cat("additional metrics:")#
print(get_metrics(conf_matrix1))#
#
print("model 2: k-nn")#
print(conf_matrix2)#
cat("additional metrics:")#
print(get_metrics(conf_matrix2))#
#
print("model 3: random forest")#
print(conf_matrix3)#
cat("additional metrics:")#
print(get_metrics(conf_matrix3))#
#
print("model 4: svm radial")#
print(conf_matrix4)#
cat("additional metrics:")#
print(get_metrics(conf_matrix4))#
#
print("model 5: xgboost")#
print(conf_matrix5)#
cat("additional metrics:")#
print(get_metrics(conf_matrix5))#
#
# 9. visualize the classifier results#
roc_curve1 <- roc(test_data$target, as.numeric(pred1))#
roc_curve2 <- roc(test_data$target, as.numeric(pred2))#
roc_curve3 <- roc(test_data$target, as.numeric(pred3))#
roc_curve4 <- roc(test_data$target, as.numeric(pred4))#
roc_curve5 <- roc(test_data$target, as.numeric(pred5))#
roc_curve_best <- roc(test_data$target, as.numeric(pred5))#
#
plot(roc_curve1, col = "blue", main = "receiver operating characteristic (roc)")#
lines(roc_curve2, col = "red")#
lines(roc_curve3, col = "green")#
lines(roc_curve4, col = "purple")#
lines(roc_curve5, col = "orange")#
#
# legend dynamically indicating the best model#
legend("bottomright", legend = c(#
  paste("model 1: logistic regression", ifelse(1 == which.max(accuracies), "(best)", "")),#
  paste("model 2: k-nn", ifelse(2 == which.max(accuracies), "(best)", "")),#
  paste("model 3: random forest", ifelse(3 == which.max(accuracies), "(best)", "")),#
  paste("model 4: svm radial", ifelse(4 == which.max(accuracies), "(best)", "")),#
  paste("model 5: xgboost", ifelse(5 == which.max(accuracies), "(best)", ""))#
), col = c("blue", "red", "green", "purple", "orange"), lty = c(1, 1, 1, 1, 1))#
#
# 10. save the model with the best accuracy.#
accuracies <- sapply(list(model1, model2, model3, model4, model5), function(model) max(model$results$Accuracy))#
best_model_index <- which.max(accuracies)#
best_model <- list(model1, model2, model3, model4, model5)[best_model_index]#
saveRDS(best_model, "best_model.rds")#
#
# print the best model name#
best_model_name <- c("logistic regression", "k-nn", "random forest", "svm radial", "xgboost")[best_model_index]#
cat("best performing model:", best_model_name, "\n")#
#
# 11. when new data comes in, predict according to the best model.#
new_data <- read.csv("newdata.csv") # change the newdata.csv to your data file for predictions. for testing purposes i have removed the target column from the dataset you have provided and predicted the results once again.#
new_data <- new_data %>% mutate_all(list(~ifelse(is.na(.), mean(., na.rm = TRUE), .)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, function(x) (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE)))#
new_data[, numeric_columns] <- apply(new_data[, numeric_columns], 2, replace_outliers)#
new_data$new_feature <- new_data$oldpeak * new_data$thalach#
#
prediction <- predict(best_model, newdata = new_data)#
cat("prediction with the best performing model:")#
print(prediction)
